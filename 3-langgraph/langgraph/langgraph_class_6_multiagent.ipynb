{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce785044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4299bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b723455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abe5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b19322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a computer program so I don't have feelings, but I'm here and ready to help. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 13, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bl55GvK4jcVGnj3RXyiegEMUPnFjW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8dbf8bcb-942f-4efb-89ea-1f7d627a4fb7-0', usage_metadata={'input_tokens': 13, 'output_tokens': 31, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi hello how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb6ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919250c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64485964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "#     Name:str\n",
    "#     age:int\n",
    "#     DOB:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5674bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number(state):\n",
    "    result=state[\"num1\"]+state[\"num2\"]\n",
    "    print(f\"addition is {result}\")\n",
    "    return Command(goto=\"multiply\",update={\"sum\":result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61dcdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"num1\":10,\"num2\":20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ada0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition is 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 30}, goto='multiply')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_number(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3be377",
   "metadata": {},
   "source": [
    "### Creating one dummy multiagent\n",
    "\n",
    "it is for network/collab multiagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e4e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06526b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\"Ask multiplication agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e610d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_addition_expert():\n",
    "    \"\"\"Ask addition agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b00032aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool=llm.bind_tools([transfer_to_multiplication_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aecb33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm_with_tool.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36429fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2499954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "466263d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm_with_tool.invoke(\"what is 2 multiply 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01c07057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f4991d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'transfer_to_multiplication_expert',\n",
       "  'args': {},\n",
       "  'id': 'call_OtB8gzmR7XBlsyEFIYYrFkr7',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11585150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langgraph.graph import MessagesState,StateGraph, START,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_expert(state:MessagesState)-> Command[Literal[\"multiplication_expert\", \"__end__\"]]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e977eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_expert(state:MessagesState)-> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4409b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd04308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bc9370c970>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"addition_agent\",additional_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a10acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bc9370c970>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"muliplication_agent\",multiplication_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c000d482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1bc9370c970>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START,\"addition_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "167451f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge ending at unknown node `additional_expert`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m app\u001b[38;5;241m=\u001b[39m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Complete_Content2\\Agentic-2.0\\env\\lib\\site-packages\\langgraph\\graph\\state.py:612\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[1;34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[0m\n\u001b[0;32m    609\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    611\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[0;32m    621\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    629\u001b[0m     ]\n\u001b[0;32m    630\u001b[0m )\n",
      "File \u001b[1;32mc:\\Complete_Content2\\Agentic-2.0\\env\\lib\\site-packages\\langgraph\\graph\\graph.py:304\u001b[0m, in \u001b[0;36mGraph.validate\u001b[1;34m(self, interrupt)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m all_targets:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;241m!=\u001b[39m END:\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge ending at unknown node `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m# validate interrupts\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interrupt:\n",
      "\u001b[1;31mValueError\u001b[0m: Found edge ending at unknown node `additional_expert`"
     ]
    }
   ],
   "source": [
    "app=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf783fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
